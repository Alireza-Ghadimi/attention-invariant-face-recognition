{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import seaborn as sns\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model initialization\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "mtcnn = MTCNN(image_size=160, margin=40, device=device, keep_all=False)\n",
    "\n",
    "# MediaPipe Face Mesh initialization\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "fallback_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Pose mapping\n",
    "POSE_MAPPING = {\n",
    "    '00': 'frontal',\n",
    "    '01': 'up',\n",
    "    '02': 'down',\n",
    "    '03': 'left',\n",
    "    '04': 'right'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29636a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# DISTANCE METRIC SELECTION\n",
    "# ============================================================================\n",
    "USE_L2_DISTANCE = True  # Set to False to use Cosine Similarity\n",
    "\n",
    "if USE_L2_DISTANCE:\n",
    "    # For L2: LOWER is better (more similar)\n",
    "    # Typical range: 0.6 to 1.2 (lower threshold = more strict)\n",
    "    SIMILARITY_THRESHOLD = 0.95  # Accept if L2 distance <= 0.95\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"USING L2 DISTANCE (Euclidean)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Threshold: {SIMILARITY_THRESHOLD} (accept if distance <= threshold)\")\n",
    "    print(f\"Lower distance = MORE similar\")\n",
    "    print(f\"Range: 0.0 (identical) to ~2.0 (very different)\")\n",
    "else:\n",
    "    # For Cosine: HIGHER is better (more similar)  \n",
    "    # Typical range: 0.4 to 0.7\n",
    "    SIMILARITY_THRESHOLD = 0.55  # Accept if cosine similarity >= 0.55\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"USING COSINE SIMILARITY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Threshold: {SIMILARITY_THRESHOLD} (accept if similarity >= threshold)\")\n",
    "    print(f\"Higher similarity = MORE similar\")\n",
    "    print(f\"Range: -1.0 to 1.0 (typically 0.3 to 0.9 for faces)\")\n",
    "\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "\"\"\"\n",
    "L2 DISTANCE vs COSINE SIMILARITY:\n",
    "==================================\n",
    "\n",
    "L2 DISTANCE (Euclidean Distance):\n",
    "  Formula: sqrt(sum((emb1 - emb2)^2))\n",
    "  Range: 0 to infinity (typically 0.4 to 2.0 for faces)\n",
    "  Interpretation: LOWER = MORE similar\n",
    "    - 0.0-0.6: Very similar (same person)\n",
    "    - 0.6-0.9: Similar (likely same person)\n",
    "    - 0.9-1.2: Somewhat similar (threshold zone)\n",
    "    - >1.2: Different people\n",
    "  Threshold: distance <= threshold → ACCEPT\n",
    "\n",
    "COSINE SIMILARITY:\n",
    "  Formula: dot(emb1, emb2) / (||emb1|| * ||emb2||)\n",
    "  Range: -1 to +1 (typically 0.3 to 0.9 for faces)\n",
    "  Interpretation: HIGHER = MORE similar\n",
    "    - 0.8-1.0: Very similar (same person)\n",
    "    - 0.6-0.8: Similar (likely same person)\n",
    "    - 0.4-0.6: Somewhat similar (threshold zone)\n",
    "    - <0.4: Different people\n",
    "  Threshold: similarity >= threshold → ACCEPT\n",
    "\n",
    "For L2-normalized embeddings (like ours):\n",
    "  L2_distance = sqrt(2 * (1 - cosine_similarity))\n",
    "  \n",
    "Recommended Thresholds:\n",
    "  L2: 0.85-1.0 (conservative), 0.7-0.85 (balanced), 0.6-0.7 (lenient)\n",
    "  Cosine: 0.55-0.60 (conservative), 0.50-0.55 (balanced), 0.45-0.50 (lenient)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5497c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def estimate_head_pose_mediapipe(image_path):\n",
    "    \"\"\"Estimate head pose using MediaPipe Face Mesh\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None, None, None, 'unknown'\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    \n",
    "    if not results.multi_face_landmarks:\n",
    "        return None, None, None, 'unknown'\n",
    "    \n",
    "    face_landmarks = results.multi_face_landmarks[0]\n",
    "    img_h, img_w = img.shape[:2]\n",
    "    \n",
    "    def get_2d_point(idx):\n",
    "        return np.array([\n",
    "            face_landmarks.landmark[idx].x * img_w,\n",
    "            face_landmarks.landmark[idx].y * img_h\n",
    "        ])\n",
    "    \n",
    "    left_eye = get_2d_point(33)\n",
    "    right_eye = get_2d_point(263)\n",
    "    nose_tip = get_2d_point(1)\n",
    "    left_mouth = get_2d_point(61)\n",
    "    right_mouth = get_2d_point(291)\n",
    "    \n",
    "    # Calculate YAW (left-right turn)\n",
    "    eye_center_x = (left_eye[0] + right_eye[0]) / 2\n",
    "    face_width = np.linalg.norm(right_eye - left_eye)\n",
    "    nose_to_center = nose_tip[0] - eye_center_x\n",
    "    yaw_ratio = nose_to_center / (face_width / 2) if face_width > 0 else 0\n",
    "    yaw = np.clip(yaw_ratio * 45, -90, 90)\n",
    "    \n",
    "    # Calculate PITCH (up-down tilt)\n",
    "    eye_center_y = (left_eye[1] + right_eye[1]) / 2\n",
    "    mouth_center_y = (left_mouth[1] + right_mouth[1]) / 2\n",
    "    face_height = abs(mouth_center_y - eye_center_y)\n",
    "    expected_nose_y = eye_center_y + 0.4 * face_height\n",
    "    nose_deviation_y = (nose_tip[1] - expected_nose_y) / face_height if face_height > 0 else 0\n",
    "    pitch = np.clip(nose_deviation_y * 60, -45, 45)\n",
    "    \n",
    "    # Calculate ROLL (head tilt)\n",
    "    eye_angle = np.arctan2(right_eye[1] - left_eye[1], right_eye[0] - left_eye[0])\n",
    "    roll = np.degrees(eye_angle)\n",
    "    \n",
    "    pose_category = categorize_pose(yaw, pitch, roll)\n",
    "    return yaw, pitch, roll, pose_category\n",
    "\n",
    "def categorize_pose(yaw, pitch, roll):\n",
    "    \"\"\"Categorize pose based on angles\"\"\"\n",
    "    if yaw is None or pitch is None:\n",
    "        return 'unknown'\n",
    "    \n",
    "    yaw_threshold = 20\n",
    "    pitch_threshold = 15\n",
    "    \n",
    "    if abs(yaw) > yaw_threshold:\n",
    "        return 'right' if yaw > 0 else 'left'\n",
    "    elif abs(pitch) > pitch_threshold:\n",
    "        return 'down' if pitch > 0 else 'up'\n",
    "    else:\n",
    "        return 'frontal'\n",
    "\n",
    "def draw_pose_annotation(image_path, yaw, pitch, roll, pose_category):\n",
    "    \"\"\"Draw pose annotation with 3D axes\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_cv = cv2.imread(image_path)\n",
    "    \n",
    "    if img_cv is None:\n",
    "        return img\n",
    "    \n",
    "    img_h, img_w = img_cv.shape[:2]\n",
    "    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "    \n",
    "    if yaw is not None and results.multi_face_landmarks:\n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        \n",
    "        nose_tip = face_landmarks.landmark[1]\n",
    "        nose_x = int(nose_tip.x * img_w)\n",
    "        nose_y = int(nose_tip.y * img_h)\n",
    "        \n",
    "        yaw_rad = np.radians(yaw)\n",
    "        pitch_rad = np.radians(pitch)\n",
    "        roll_rad = np.radians(roll)\n",
    "        \n",
    "        axis_length = min(img_w, img_h) // 5\n",
    "        \n",
    "        # Calculate axis endpoints\n",
    "        x_end_x = int(nose_x + axis_length * np.cos(pitch_rad))\n",
    "        x_end_y = int(nose_y - axis_length * np.sin(pitch_rad))\n",
    "        \n",
    "        y_end_x = int(nose_x + axis_length * np.sin(yaw_rad))\n",
    "        y_end_y = int(nose_y)\n",
    "        \n",
    "        z_end_x = int(nose_x + axis_length * 0.3 * np.sin(yaw_rad))\n",
    "        z_end_y = int(nose_y - axis_length * 0.3 * np.cos(pitch_rad))\n",
    "        \n",
    "        # Draw axes\n",
    "        cv2.line(img_cv, (nose_x, nose_y), (z_end_x, z_end_y), (255, 0, 0), 3)\n",
    "        cv2.circle(img_cv, (z_end_x, z_end_y), 5, (255, 0, 0), -1)\n",
    "        \n",
    "        cv2.line(img_cv, (nose_x, nose_y), (x_end_x, x_end_y), (0, 0, 255), 3)\n",
    "        cv2.circle(img_cv, (x_end_x, x_end_y), 5, (0, 0, 255), -1)\n",
    "        \n",
    "        cv2.line(img_cv, (nose_x, nose_y), (y_end_x, y_end_y), (0, 255, 0), 3)\n",
    "        cv2.circle(img_cv, (y_end_x, y_end_y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        cv2.circle(img_cv, (nose_x, nose_y), 7, (255, 255, 255), -1)\n",
    "        cv2.circle(img_cv, (nose_x, nose_y), 7, (0, 0, 0), 2)\n",
    "        \n",
    "        img = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if yaw is not None:\n",
    "        text = f\"Yaw: {yaw:.1f}° (Green)\\nPitch: {pitch:.1f}° (Red)\\nRoll: {roll:.1f}°\\nPose: {pose_category}\"\n",
    "    else:\n",
    "        text = f\"Pose: {pose_category}\"\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 12)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    bbox = draw.textbbox((10, 10), text, font=font)\n",
    "    draw.rectangle(bbox, fill=(0, 0, 0, 180))\n",
    "    draw.text((10, 10), text, fill=(0, 255, 255), font=font)\n",
    "    \n",
    "    legend_y = img.height - 80\n",
    "    legend_text = \"Axes:\\nRed = Pitch\\nGreen = Yaw\\nBlue = Forward\"\n",
    "    legend_bbox = draw.textbbox((10, legend_y), legend_text, font=font)\n",
    "    draw.rectangle(legend_bbox, fill=(0, 0, 0, 180))\n",
    "    draw.text((10, legend_y), legend_text, fill=(255, 255, 255), font=font)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769835b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_embedding(img_path):\n",
    "    \"\"\"Extract face embedding from image\"\"\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    face_tensor = mtcnn(img)\n",
    "    \n",
    "    if face_tensor is None:\n",
    "        face_tensor = fallback_transform(img)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        face_tensor = face_tensor.unsqueeze(0).to(device)\n",
    "        embedding = model(face_tensor)\n",
    "        embedding = F.normalize(embedding, p=2, dim=1)\n",
    "    \n",
    "    return embedding.cpu().numpy().flatten()\n",
    "\n",
    "def calculate_similarity(emb1, emb2):\n",
    "    \"\"\"\n",
    "    Calculate similarity between two embeddings\n",
    "    Returns similarity score based on selected metric\n",
    "    \"\"\"\n",
    "    if USE_L2_DISTANCE:\n",
    "        # L2 Distance (Euclidean)\n",
    "        distance = np.linalg.norm(emb1 - emb2)\n",
    "        return distance  # Lower is better\n",
    "    else:\n",
    "        # Cosine Similarity\n",
    "        similarity = np.dot(emb1, emb2)\n",
    "        return similarity  # Higher is better\n",
    "\n",
    "def attention_score(query_emb, gallery_embs, temperature=1.0):\n",
    "    \"\"\"Calculate attention-weighted similarity score\"\"\"\n",
    "    sims = np.array([calculate_similarity(query_emb, g) for g in gallery_embs])\n",
    "    \n",
    "    if USE_L2_DISTANCE:\n",
    "        # For L2: convert to similarity-like scores (negative distances)\n",
    "        exp_sims = np.exp(-sims / temperature)\n",
    "    else:\n",
    "        # For Cosine: use as-is\n",
    "        exp_sims = np.exp(sims / temperature)\n",
    "    \n",
    "    attention = exp_sims / np.sum(exp_sims)\n",
    "    \n",
    "    if USE_L2_DISTANCE:\n",
    "        # Weighted average of distances (lower is better)\n",
    "        S_p = np.sum(attention * sims)\n",
    "    else:\n",
    "        # Weighted average of similarities (higher is better)\n",
    "        S_p = np.sum(attention * sims)\n",
    "    \n",
    "    return S_p, attention, sims\n",
    "\n",
    "def pose_specific_score(query_emb, gallery_dict, estimated_pose):\n",
    "    \"\"\"Calculate similarity focusing on matching pose\"\"\"\n",
    "    all_scores = {}\n",
    "    \n",
    "    for person_id, pose_data in gallery_dict.items():\n",
    "        pose_sims = {}\n",
    "        for pose_id, emb in pose_data.items():\n",
    "            sim = calculate_similarity(query_emb, emb)\n",
    "            pose_name = POSE_MAPPING.get(pose_id, pose_id)\n",
    "            pose_sims[pose_name] = sim\n",
    "        \n",
    "        gallery_embs = list(pose_data.values())\n",
    "        overall_score, attention, sims = attention_score(query_emb, gallery_embs)\n",
    "        \n",
    "        if estimated_pose in pose_sims:\n",
    "            pose_specific = pose_sims[estimated_pose]\n",
    "        else:\n",
    "            if USE_L2_DISTANCE:\n",
    "                pose_specific = min(pose_sims.values())  # Minimum distance\n",
    "            else:\n",
    "                pose_specific = max(pose_sims.values())  # Maximum similarity\n",
    "        \n",
    "        all_scores[person_id] = {\n",
    "            'overall': overall_score,\n",
    "            'pose_specific': pose_specific,\n",
    "            'pose_sims': pose_sims,\n",
    "            'attention': attention,\n",
    "            'all_sims': sims\n",
    "        }\n",
    "    \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meets_threshold(score):\n",
    "    \"\"\"Check if score meets the threshold based on metric type\"\"\"\n",
    "    if USE_L2_DISTANCE:\n",
    "        return score <= SIMILARITY_THRESHOLD  # Lower is better\n",
    "    else:\n",
    "        return score >= SIMILARITY_THRESHOLD  # Higher is better\n",
    "\n",
    "def get_best_match(all_scores, method='pose_specific'):\n",
    "    \"\"\"Get best matching person based on scores\"\"\"\n",
    "    if USE_L2_DISTANCE:\n",
    "        # Find minimum distance\n",
    "        best_person = min(all_scores.keys(), key=lambda p: all_scores[p][method])\n",
    "    else:\n",
    "        # Find maximum similarity\n",
    "        best_person = max(all_scores.keys(), key=lambda p: all_scores[p][method])\n",
    "    \n",
    "    best_score = all_scores[best_person][method]\n",
    "    return best_person, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13842032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# UPDATE THIS PATH\n",
    "BASE_PATH = 'E:/Projects/cv1'\n",
    "\n",
    "# Build gallery\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING GALLERY WITH MEDIAPIPE HEAD POSE ESTIMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gallery_ids = ['00', '01', '02', '03', '04', '05', '06']\n",
    "gallery_dict = {}\n",
    "gallery_images = {}\n",
    "gallery_poses = {}\n",
    "\n",
    "for person_id in gallery_ids:\n",
    "    folder_path = os.path.join(BASE_PATH, \"gallery\", person_id)\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Warning: Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    \n",
    "    pose_embeddings = {}\n",
    "    person_images = {}\n",
    "    person_poses = {}\n",
    "    \n",
    "    print(f\"\\nProcessing gallery person {person_id}:\")\n",
    "    for img_name in sorted(os.listdir(folder_path)):\n",
    "        if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "            \n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        pose_id = img_name.split('.')[0]\n",
    "        \n",
    "        yaw, pitch, roll, pose_cat = estimate_head_pose_mediapipe(img_path)\n",
    "        person_poses[pose_id] = {\n",
    "            'yaw': yaw, 'pitch': pitch, 'roll': roll, \n",
    "            'category': pose_cat, 'expected': POSE_MAPPING.get(pose_id, 'unknown')\n",
    "        }\n",
    "        \n",
    "        print(f\"  {pose_id}.jpg: Expected={POSE_MAPPING.get(pose_id, 'unknown'):>8} | \"\n",
    "              f\"Detected={pose_cat:>8} | Yaw={yaw:>6.1f}° Pitch={pitch:>6.1f}° Roll={roll:>6.1f}°\" \n",
    "              if yaw is not None else f\"  {pose_id}.jpg: Pose detection failed\")\n",
    "        \n",
    "        emb = extract_embedding(img_path)\n",
    "        pose_embeddings[pose_id] = emb\n",
    "        person_images[pose_id] = Image.open(img_path)\n",
    "    \n",
    "    gallery_dict[person_id] = pose_embeddings\n",
    "    gallery_images[person_id] = person_images\n",
    "    gallery_poses[person_id] = person_poses\n",
    "\n",
    "print(f\"\\nGallery built with {len(gallery_dict)} people\")\n",
    "\n",
    "# Process queries\n",
    "queries_path = os.path.join(BASE_PATH, 'queries')\n",
    "\n",
    "if not os.path.exists(queries_path):\n",
    "    raise FileNotFoundError(f\"Queries folder not found: {queries_path}\")\n",
    "\n",
    "query_files = sorted([f for f in os.listdir(queries_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"PROCESSING ALL QUERIES WITH THRESHOLD = {SIMILARITY_THRESHOLD}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "pose_specific_results = {pose: [] for pose in POSE_MAPPING.values()}\n",
    "pose_specific_results['unknown'] = []\n",
    "\n",
    "for query_name in query_files:\n",
    "    query_path = os.path.join(queries_path, query_name)\n",
    "    \n",
    "    yaw, pitch, roll, estimated_pose = estimate_head_pose_mediapipe(query_path)\n",
    "    query_emb = extract_embedding(query_path)\n",
    "    \n",
    "    parts = query_name.split('_')\n",
    "    if len(parts) >= 2:\n",
    "        potential_id = parts[1].split('.')[0]\n",
    "        if potential_id == '07':\n",
    "            ground_truth = 'unknown'\n",
    "        elif potential_id in gallery_ids:\n",
    "            ground_truth = potential_id\n",
    "        else:\n",
    "            ground_truth = 'unknown'\n",
    "    else:\n",
    "        ground_truth = 'unknown'\n",
    "    \n",
    "    is_known = ground_truth in gallery_ids\n",
    "    \n",
    "    all_scores = pose_specific_score(query_emb, gallery_dict, estimated_pose)\n",
    "    \n",
    "    # Baseline prediction\n",
    "    predicted_overall_id, score_overall = get_best_match(all_scores, 'overall')\n",
    "    if meets_threshold(score_overall):\n",
    "        final_prediction_overall = predicted_overall_id\n",
    "        meets_threshold_overall = True\n",
    "    else:\n",
    "        final_prediction_overall = 'unknown'\n",
    "        meets_threshold_overall = False\n",
    "    \n",
    "    # Pose-aware prediction\n",
    "    predicted_pose_id, score_pose = get_best_match(all_scores, 'pose_specific')\n",
    "    if meets_threshold(score_pose):\n",
    "        final_prediction_pose = predicted_pose_id\n",
    "        meets_threshold_pose = True\n",
    "    else:\n",
    "        final_prediction_pose = 'unknown'\n",
    "        meets_threshold_pose = False\n",
    "    \n",
    "    result = {\n",
    "        'query': query_name,\n",
    "        'ground_truth': ground_truth,\n",
    "        'is_known': is_known,\n",
    "        'yaw': yaw,\n",
    "        'pitch': pitch,\n",
    "        'roll': roll,\n",
    "        'estimated_pose': estimated_pose,\n",
    "        'predicted_overall': final_prediction_overall,\n",
    "        'score_overall': score_overall,\n",
    "        'meets_threshold_overall': meets_threshold_overall,\n",
    "        'predicted_pose_specific': final_prediction_pose,\n",
    "        'score_pose_specific': score_pose,\n",
    "        'meets_threshold_pose': meets_threshold_pose,\n",
    "        'best_match_id': predicted_pose_id,\n",
    "        'best_match_score': score_pose,\n",
    "        'correct_overall': (final_prediction_overall == ground_truth),\n",
    "        'correct_pose_specific': (final_prediction_pose == ground_truth),\n",
    "        'all_scores': all_scores\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    pose_specific_results[estimated_pose].append(result)\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} queries\")\n",
    "\n",
    "# Generate results table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS TABLE - ALL QUERIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_table = []\n",
    "for r in results:\n",
    "    row = {\n",
    "        'filename': r['query'],\n",
    "        'true_id': r['ground_truth'],\n",
    "        'pred_id': r['predicted_pose_specific'],\n",
    "        'score': r['score_pose_specific'],\n",
    "        'correct': 1 if r['correct_pose_specific'] else 0\n",
    "    }\n",
    "    results_table.append(row)\n",
    "\n",
    "print(f\"\\n{'filename':<20} {'true_id':<10} {'pred_id':<10} {'score':<12} {'correct':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for row in results_table:\n",
    "    print(f\"{row['filename']:<20} {row['true_id']:<10} {row['pred_id']:<10} {row['score']:<12.5f} {row['correct']:<10}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = os.path.join(BASE_PATH, f'results_table_{\"L2\" if USE_L2_DISTANCE else \"cosine\"}.csv')\n",
    "with open(csv_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['filename', 'true_id', 'pred_id', 'score', 'correct']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in results_table:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"\\n✓ Results table saved to: {csv_path}\")\n",
    "\n",
    "correct_count = sum(row['correct'] for row in results_table)\n",
    "total_count = len(results_table)\n",
    "accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "\n",
    "print(f\"\\nTable Summary:\")\n",
    "print(f\"  Total Queries: {total_count}\")\n",
    "print(f\"  Correct: {correct_count}\")\n",
    "print(f\"  Incorrect: {total_count - correct_count}\")\n",
    "print(f\"  Accuracy: {accuracy:.3f} ({100*accuracy:.1f}%)\")\n",
    "\n",
    "print(f\"\\nBreakdown by True ID:\")\n",
    "print(f\"  {'ID':<10} {'Total':<10} {'Correct':<10} {'Accuracy':<10}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for class_id in sorted(set(row['true_id'] for row in results_table)):\n",
    "    class_rows = [r for r in results_table if r['true_id'] == class_id]\n",
    "    class_total = len(class_rows)\n",
    "    class_correct = sum(r['correct'] for r in class_rows)\n",
    "    class_acc = class_correct / class_total if class_total > 0 else 0\n",
    "    print(f\"  {class_id:<10} {class_total:<10} {class_correct:<10} {class_acc:<10.3f}\")\n",
    "\n",
    "# Comparison section\n",
    "known_results = [r for r in results if r['is_known']]\n",
    "unknown_results = [r for r in results if not r['is_known']]\n",
    "truly_unknown_results = unknown_results\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE vs POSE-AWARE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "known_results_temp = [r for r in results if r['is_known']]\n",
    "\n",
    "baseline_correct = sum(1 for r in known_results_temp if r['correct_overall'])\n",
    "pose_correct = sum(1 for r in known_results_temp if r['correct_pose_specific'])\n",
    "total_known = len(known_results_temp)\n",
    "\n",
    "print(f\"\\n{'Method':<20} {'Correct':<15} {'Accuracy':<15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'BASELINE':<20} {baseline_correct}/{total_known:<14} {100*baseline_correct/total_known if total_known > 0 else 0:>6.1f}%\")\n",
    "print(f\"{'POSE-AWARE':<20} {pose_correct}/{total_known:<14} {100*pose_correct/total_known if total_known > 0 else 0:>6.1f}%\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "improvement = pose_correct - baseline_correct\n",
    "improvement_pct = 100 * improvement / total_known if total_known > 0 else 0\n",
    "print(f\"{'IMPROVEMENT':<20} {'+' if improvement >= 0 else ''}{improvement:<14} {'+' if improvement_pct >= 0 else ''}{improvement_pct:>6.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nMetric Used: {'L2 Distance' if USE_L2_DISTANCE else 'Cosine Similarity'}\")\n",
    "print(f\"Threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"{'Lower is better' if USE_L2_DISTANCE else 'Higher is better'}\")\n",
    "print(f\"\\nResults saved to: {csv_path}\")\n",
    "\n",
    "# Cleanup\n",
    "face_mesh.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
